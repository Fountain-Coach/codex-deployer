# üöÄ ‚ÄúLLM-First‚Äù Typesense GUI ‚Äî Concept Brief

![[TypesenseGui-Mock.png]]

*A chat-centric interface that lets Codex / GPT prompts drive search, while giving humans instant, transparent insight into what Typesense is doing under the hood.*

---

## 1‚ÄÇDesign Goals

| Goal | Why it matters |
|------|----------------|
| **Chat is the primary control surface** | Prompts originate from agents (Codex, GPT-4o, etc.) or a human operator. |
| **Transparent retrieval** | Show which documents, filters, embeddings, and ranking rules produced each answer. |
| **Rapid iteration loop** | Let users tweak the prompt, system instructions, or RAG parameters and re-run instantly. |
| **Corpus-aware** | Surface FountainAI corpora & semantic filters so the LLM can switch context on the fly. |
| **Ops-grade visibility** | Latency, token + vector costs, node health, and API usage visible at a glance. |

---

## 2‚ÄÇKey Screens & Components

| Screen | Purpose | Essential Widgets |
|--------|---------|-------------------|
| **Chat Workspace** | Primary prompt / reply view | ‚Ä¢ Prompt composer (system / tool / user roles)<br>‚Ä¢ Streaming LLM answer<br>‚Ä¢ Inline citation chips linked to Typesense hits |
| **Retrieval Inspector** | Side-by-side diff of LLM text ‚ÜîÔ∏é Typesense results | ‚Ä¢ Ranked hit table (score, highlight, distance)<br>‚Ä¢ Raw JSON toggle<br>‚Ä¢ ‚ÄúRe-rank‚Äù button |
| **Prompt History** | Rewind & branch conversations | ‚Ä¢ Timeline showing tool calls, retries, errors<br>‚Ä¢ One-click ‚Äúfork‚Äù into new tab |
| **Schema & Corpus Browser** | Manage collections without leaving chat | ‚Ä¢ Tree of corpora ‚Üí collections ‚Üí fields<br>‚Ä¢ Quick actions: clone, toggle embeddings, add synonym |
| **Ops Dashboard** | Keep the cluster & billing healthy | ‚Ä¢ QPS, latency, error-rate graphs<br>‚Ä¢ Token + vector cost estimator ‚ìò<br>‚Ä¢ Node status (green / amber / red) |

---

## 3‚ÄÇInteraction Flow

1. **Enter / receive prompt** ‚Üí GUI forwards to LLM.  
2. **LLM calls `typesense.search`** ‚Üí GUI shows *‚Äúüîé Searching‚Ä¶‚Äù*.  
3. **Typesense responds** with JSON hits & metrics.  
4. **LLM streams final answer**; citations render as expandable chips.  
5. **User or agent tweaks** corpus / filters ‚Üí loop back to step 2 (hot-reload).

---

## 4‚ÄÇUnder-the-Hood Architecture

```mermaid
graph TD
    A[SwiftUI Chat View] -->|Prompt| LLM
    LLM -->|Tool call: typesense.search| TSClient
    TSClient -->|REST / RAG API| TypesenseCluster
    TypesenseCluster --> TSClient
    TSClient --> LLM
    LLM -->|Answer + citations| A
    TSClient -->|Raw hits & metrics| InspectorView
    TypesenseCluster -->|Metrics| OpsDashboard
```

---

## 5‚ÄÇUI Details & Best Practices

- **Dual-pane layout**: chat left, inspector right (auto-collapse on mobile).  
- **Hotkeys**: ‚áß‚èé send, ‚å•‚Üë/‚Üì cycle prompts, ‚åòP collection palette.  
- **Theming**: Tailwind-inspired tokens in TeatroViewEngine; honours system dark mode.  
- **Streaming UX**: SSE / WebSocket; show token counter + latency badge live.  
- **Security**: Role-based JWT; scoped API keys injected into tool calls; clipboard redaction for PII.

---

## 6‚ÄÇPriority Evaluation for Codex-Deployer

The Codex-deployer currently automates Swift builds and patch application across the FountainAI monorepo. TeatroView already includes a minimal Typesense GUI, and the workflow generates a Typesense client from the OpenAPI spec.

1. **Tooling readiness** ‚Äì The dispatcher handles builds but lacks explicit hooks for live UI reloads.
2. **Client generation** ‚Äì Existing scripts produce a usable Typesense client, so the GUI can rely on those artifacts.
3. **Roadmap fit** ‚Äì The project roadmap mentions a visual dashboard, aligning with this GUI's inspector and ops views.

Overall priority: **Medium**. Implementing the LLM-first GUI complements current tasks but should not block core deployment features.

````text
¬©\ 2025 Contexter alias Benedikt Eickhoff üõ°Ô∏è All rights reserved.
````

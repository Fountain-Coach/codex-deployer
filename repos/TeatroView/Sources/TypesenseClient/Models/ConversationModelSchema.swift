//
// ConversationModelSchema.swift
//
// Generated by openapi-generator
// https://openapi-generator.tech
//

import Foundation

public struct ConversationModelSchema: Sendable, Codable, ParameterConvertible, Hashable {

    /** An explicit id for the model, otherwise the API will return a response with an auto-generated conversation model id. */
    public var id: String
    /** Name of the LLM model offered by OpenAI, Cloudflare or vLLM */
    public var modelName: String
    /** The LLM service's API Key */
    public var apiKey: String?
    /** Typesense collection that stores the historical conversations */
    public var historyCollection: String
    /** LLM service's account ID (only applicable for Cloudflare) */
    public var accountId: String?
    /** The system prompt that contains special instructions to the LLM */
    public var systemPrompt: String?
    /** Time interval in seconds after which the messages would be deleted. Default: 86400 (24 hours)  */
    public var ttl: Int?
    /** The maximum number of bytes to send to the LLM in every API call. Consult the LLM's documentation on the number of bytes supported in the context window.  */
    public var maxBytes: Int
    /** URL of vLLM service */
    public var vllmUrl: String?

    public init(id: String, modelName: String, apiKey: String? = nil, historyCollection: String, accountId: String? = nil, systemPrompt: String? = nil, ttl: Int? = nil, maxBytes: Int, vllmUrl: String? = nil) {
        self.id = id
        self.modelName = modelName
        self.apiKey = apiKey
        self.historyCollection = historyCollection
        self.accountId = accountId
        self.systemPrompt = systemPrompt
        self.ttl = ttl
        self.maxBytes = maxBytes
        self.vllmUrl = vllmUrl
    }

    public enum CodingKeys: String, CodingKey, CaseIterable {
        case id
        case modelName = "model_name"
        case apiKey = "api_key"
        case historyCollection = "history_collection"
        case accountId = "account_id"
        case systemPrompt = "system_prompt"
        case ttl
        case maxBytes = "max_bytes"
        case vllmUrl = "vllm_url"
    }

    // Encodable protocol methods

    public func encode(to encoder: Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        try container.encode(id, forKey: .id)
        try container.encode(modelName, forKey: .modelName)
        try container.encodeIfPresent(apiKey, forKey: .apiKey)
        try container.encode(historyCollection, forKey: .historyCollection)
        try container.encodeIfPresent(accountId, forKey: .accountId)
        try container.encodeIfPresent(systemPrompt, forKey: .systemPrompt)
        try container.encodeIfPresent(ttl, forKey: .ttl)
        try container.encode(maxBytes, forKey: .maxBytes)
        try container.encodeIfPresent(vllmUrl, forKey: .vllmUrl)
    }
}


@available(iOS 13, tvOS 13, watchOS 6, macOS 10.15, *)
extension ConversationModelSchema: Identifiable {}

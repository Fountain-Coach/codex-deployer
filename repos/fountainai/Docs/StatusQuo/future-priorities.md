# Future Priorities

The status reports show that all FountainAI services are generated but remain largely skeletal:
- Servers compile and print startup messages but lack an HTTP runtime.
- Clients decode responses as raw `Data` and models are untyped.
- No persistence layer or external integrations are wired up.
- Unit tests exercise only the generator, not service behavior.

To progress toward a functional release we should:

1. **Implement typed models** â€“ expand the parser and generators so requests and responses use concrete Swift types shared by clients and servers.
2. **Add a minimal HTTP runtime** â€“ integrate a SwiftNIO-based listener so each generated server can process requests concurrently.
3. **Connect external dependencies** â€“ wire the Persistence service to Typesense and hook the Planner and Function Caller into the LLM Gateway.
4. **Introduce integration tests** â€“ use the generated SDKs to call the running servers and verify endâ€‘toâ€‘end flows.
5. **Automate CI and container builds** â€“ run `swift build` and `swift test` on every pull request and document Docker workflows for deployment.
6. **Update the execution plan** â€“ reconcile `Docs/Historical/codex-plan.md` with completed work and these new tasks.

```` text
Â©\ 2025 Contexter alias Benedikt Eickhoff ğŸ›¡ï¸ All rights reserved.
````
